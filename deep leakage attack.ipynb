{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925f29e5-f916-4536-9e1d-16d4d2d6c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as torch_init\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21d2204-162d-47e4-867a-1195acc23116",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_delta_tensor = torch.load('files/selected_delta.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579c06f2-ceb5-495a-933f-874c9146a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight torch.Size([512, 64])\n",
      "fc1.bias torch.Size([512])\n",
      "fc_att1.0.weight torch.Size([512, 64])\n",
      "fc_att1.0.bias torch.Size([512])\n",
      "fc2.weight torch.Size([32, 512])\n",
      "fc2.bias torch.Size([32])\n",
      "fc_att2.0.weight torch.Size([32, 512])\n",
      "fc_att2.0.bias torch.Size([32])\n",
      "fc3.weight torch.Size([1, 32])\n",
      "fc3.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for key, value in selected_delta_tensor.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6676d2-5680-406a-8e21-38d43204b292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 64]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "sample_data = torch.load('files/training_data1.pt', map_location=torch.device('cpu'))\n",
    "sample_label = torch.load('files/training_labels1.pt', map_location=torch.device('cpu'))\n",
    "print(sample_data.shape, sample_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b6278c-d351-4cc8-b438-272efd5edde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_delete = ['fc_att1.0.weight', 'fc_att1.0.bias', 'fc_att2.0.weight', 'fc_att2.0.bias' ]\n",
    "for key in keys_to_delete:\n",
    "    del selected_delta_tensor[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c269d42-8454-428e-9790-8acfb2f52d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find('Linear') != -1:\n",
    "        torch_init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "class C2FPL_ucf(nn.Module): # multiplication then Addition\n",
    "    def __init__(self):\n",
    "        super(C2FPL_ucf, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 512)\n",
    "\n",
    "        self.fc_att1 = nn.Sequential(nn.Linear(64, 512), nn.Softmax(dim = 1))\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 32)\n",
    "\n",
    "        self.fc_att2 = nn.Sequential(nn.Linear(512, 32), nn.Softmax(dim = 1))\n",
    "\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.apply(weight_init)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        bs , ncrops, f = inputs.size()\n",
    "        x = self.fc1(inputs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "\n",
    "        x = x.mean(dim = 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "net = C2FPL_ucf().to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6353fc6-3f1e-4c8c-aab9-cfd6fad0464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_delta = list(value.clone() for _, value in selected_delta_tensor.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d02f183-66d1-4945-8d6b-189a7376d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_matrix = torch.rand(1, 10, 64, requires_grad=True).to(\"cpu\")\n",
    "dummy_label = torch.rand(1, 1, dtype=torch.float32, requires_grad=True).to(\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9abc3df6-9125-4a66-903f-0717a0ff5bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_for_onehot(pred, target):\n",
    "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))\n",
    "criterion = cross_entropy_for_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42104897-0997-4c6d-9da6-90033af34d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.1000\n",
      "1000 13.1131\n",
      "2000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "3000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "4000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "5000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "6000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "7000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "8000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "9000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "10000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "11000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "12000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "13000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "14000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "15000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "16000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "17000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "18000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "19000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "20000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "21000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "22000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "23000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "24000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "25000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "26000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "27000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "28000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n",
      "29000 13.1131\n",
      "Loss stuck at 13.1131, adding randomness to dummy_matrix.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.LBFGS([dummy_matrix, dummy_label] )\n",
    "lr = 0.01 # this value is used as the default one and not been changed. line 80\n",
    "history = []\n",
    "stuck = False\n",
    "best_loss = float('inf') \n",
    "\n",
    "def add_randomness(tensor, noise_factor=0.0001):\n",
    "    noise = torch.randn_like(tensor) * noise_factor\n",
    "    new_tensor = tensor + noise\n",
    "    new_tensor = new_tensor.detach().clone() \n",
    "    new_tensor.requires_grad = True  \n",
    "    return new_tensor\n",
    "\n",
    "for iters in range(30000):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        pred = net(dummy_matrix)\n",
    "        # dummy_label.data = F.sigmoid(dummy_label.data)\n",
    "        # print(pred, dummy_label)\n",
    "        dummy_loss = torch.nn.BCEWithLogitsLoss()(pred, dummy_label)\n",
    "\n",
    "        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True, allow_unused=True)\n",
    "        weight_updates = [-lr * grad for grad in dummy_dy_dx if grad is not None] # W_t+1 - W_t = -n * grad\n",
    "\n",
    "        grad_diff = 0\n",
    "        grad_count = 0\n",
    "\n",
    "        for gx, gy in zip(weight_updates, copy_delta):\n",
    "            grad_diff += ((gx - gy) ** 2).sum()\n",
    "\n",
    "        grad_diff.backward()\n",
    "        return grad_diff\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    # scheduler.step()\n",
    "    \n",
    "    if iters % 1000 == 0:\n",
    "        current_loss = closure().item()\n",
    "        print(iters, \"%.4f\" % current_loss)\n",
    "\n",
    "        # Checking if the loss is stagnating\n",
    "        if abs(current_loss - best_loss) < 0.0001:\n",
    "            stuck = True\n",
    "        else:\n",
    "            stuck = False\n",
    "            best_loss = current_loss  \n",
    "\n",
    "        # If the loss is stuck for too many iterations, then I am adding randomness to escape local minima\n",
    "        if stuck == True: \n",
    "            print(\"Loss stuck at {:.4f}, adding randomness to dummy_matrix.\".format(current_loss))\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            torch.save(dummy_matrix, 'dummy_matrix.pt')\n",
    "\n",
    "            dummy_matrix = add_randomness(dummy_matrix)\n",
    "\n",
    "            # Reloading the optimizer with new dummy_matrix\n",
    "            optimizer = torch.optim.Adam([dummy_matrix, dummy_label], lr=current_lr*0.5)\n",
    "            # optimizer = torch.optim.LBFGS([dummy_matrix, dummy_label] )\n",
    "\n",
    "            stuck = False  # Reset counter\n",
    "\n",
    "        history.append(dummy_matrix.clone().detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6696e-eba8-42a2-9371-cf8b7d203283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
