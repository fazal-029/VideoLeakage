{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925f29e5-f916-4536-9e1d-16d4d2d6c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as torch_init\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21d2204-162d-47e4-867a-1195acc23116",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_delta_tensor = torch.load('files/selected_delta.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579c06f2-ceb5-495a-933f-874c9146a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body.0.weight torch.Size([12, 10, 5, 5])\n",
      "body.0.bias torch.Size([12])\n",
      "body.2.weight torch.Size([12, 12, 5, 5])\n",
      "body.2.bias torch.Size([12])\n",
      "body.4.weight torch.Size([12, 12, 5, 5])\n",
      "body.4.bias torch.Size([12])\n",
      "body.6.weight torch.Size([12, 12, 5, 5])\n",
      "body.6.bias torch.Size([12])\n",
      "fc.0.weight torch.Size([1, 192])\n",
      "fc.0.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for key, value in selected_delta_tensor.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6676d2-5680-406a-8e21-38d43204b292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 64]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "ground_truth_data = torch.load('files/training_data1.pt', map_location=torch.device('cpu'))\n",
    "ground_truth_label = torch.load('files/training_labels1.pt', map_location=torch.device('cpu'))\n",
    "print(ground_truth_data.shape, ground_truth_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c269d42-8454-428e-9790-8acfb2f52d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find('Linear') != -1:\n",
    "        torch_init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "class lenet_used_to_generate_gradients_ucf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lenet_used_to_generate_gradients_ucf, self).__init__()\n",
    "        act = nn.Sigmoid \n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(10, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "            act()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(192, 1),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        current_tensor = inputs.unsqueeze(2)\n",
    "        \n",
    "        out = self.body(current_tensor)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        out = out.squeeze(-1) \n",
    "        \n",
    "        return out\n",
    "        \n",
    "net = lenet_used_to_generate_gradients_ucf().to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6353fc6-3f1e-4c8c-aab9-cfd6fad0464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_delta = list(value.clone() for _, value in selected_delta_tensor.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d02f183-66d1-4945-8d6b-189a7376d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_matrix = torch.rand(ground_truth_data.size(), requires_grad=True).to(\"cpu\")\n",
    "dummy_label = torch.rand(ground_truth_label.size(), dtype=torch.float32, requires_grad=True).to(\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42104897-0997-4c6d-9da6-90033af34d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1005\n",
      "1000 0.7870\n",
      "2000 0.5504\n",
      "3000 0.3763\n",
      "4000 0.2546\n",
      "5000 0.1770\n",
      "6000 0.1347\n",
      "7000 0.1173\n",
      "8000 0.1130\n",
      "9000 0.1126\n",
      "Loss stuck at 0.1126, adding randomness to dummy_matrix.\n",
      "10000 0.1126\n",
      "Loss stuck at 0.1126, adding randomness to dummy_matrix.\n",
      "11000 0.1126\n",
      "Loss stuck at 0.1126, adding randomness to dummy_matrix.\n",
      "12000 0.1126\n",
      "Loss stuck at 0.1126, adding randomness to dummy_matrix.\n",
      "13000 0.1126\n",
      "Loss stuck at 0.1126, adding randomness to dummy_matrix.\n",
      "14000 0.1126\n",
      "Loss stuck at 0.1126, adding randomness to dummy_matrix.\n",
      "15000 0.1126\n",
      "Loss stuck at 0.1126, adding randomness to dummy_matrix.\n",
      "16000 0.1126\n",
      "Loss stuck at 0.1126, adding randomness to dummy_matrix.\n",
      "17000 0.1126\n",
      "Loss stuck at 0.1126, adding randomness to dummy_matrix.\n",
      "18000 0.1126\n",
      "Loss stuck at 0.1126, adding randomness to dummy_matrix.\n",
      "19000 0.1126\n",
      "Loss stuck at 0.1126, adding randomness to dummy_matrix.\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.LBFGS([dummy_matrix, dummy_label])\n",
    "lr = 0.01 # this value is used as the default one and not been changed. line 80\n",
    "optimizer = torch.optim.Adam([dummy_matrix, dummy_label], lr=lr)\n",
    "\n",
    "history = []\n",
    "stuck = False\n",
    "best_loss = float('inf') \n",
    "\n",
    "def add_randomness(tensor, noise_factor=0.001):\n",
    "    noise = torch.randn_like(tensor) * noise_factor\n",
    "    new_tensor = tensor + noise\n",
    "    new_tensor = new_tensor.detach().clone() \n",
    "    new_tensor.requires_grad = True  \n",
    "    return new_tensor\n",
    "\n",
    "for iters in range(20000):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        pred = net(dummy_matrix)\n",
    "        # dummy_label.data = F.sigmoid(dummy_label.data)\n",
    "        # print(pred, dummy_label)\n",
    "        dummy_loss = torch.nn.BCEWithLogitsLoss()(pred, dummy_label)\n",
    "\n",
    "        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True, allow_unused=True)\n",
    "        weight_updates = [-lr * grad for grad in dummy_dy_dx if grad is not None] # W_t+1 - W_t = -n * grad\n",
    "\n",
    "        grad_diff = 0\n",
    "        grad_count = 0\n",
    "\n",
    "        for gx, gy in zip(weight_updates, copy_delta):\n",
    "            grad_diff += ((gx - gy) ** 2).sum()\n",
    "\n",
    "        grad_diff.backward()\n",
    "        return grad_diff\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    # scheduler.step()\n",
    "    \n",
    "    if iters % 1000 == 0:\n",
    "        current_loss = closure().item()\n",
    "        print(iters, \"%.4f\" % current_loss)\n",
    "        # print(dummy_matrix[0][0][:5])\n",
    "\n",
    "        # Checking if the loss is stagnating\n",
    "        if abs(current_loss - best_loss) < 0.001:\n",
    "            stuck = True\n",
    "        else:\n",
    "            stuck = False\n",
    "            best_loss = current_loss  \n",
    "\n",
    "        # If the loss is stuck for too many iterations, then I am adding randomness to escape local minima\n",
    "        if stuck == True: \n",
    "            print(\"Loss stuck at {:.4f}, adding randomness to dummy_matrix.\".format(current_loss))\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            torch.save(dummy_matrix, 'dummy_matrix.pt')\n",
    "\n",
    "            dummy_matrix = add_randomness(dummy_matrix)\n",
    "\n",
    "            # Reloading the optimizer with new dummy_matrix\n",
    "            optimizer = torch.optim.Adam([dummy_matrix, dummy_label], lr=current_lr*0.5)\n",
    "\n",
    "            stuck = False  # Reset counter\n",
    "\n",
    "        history.append(dummy_matrix.clone().detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44b6696e-eba8-42a2-9371-cf8b7d203283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1721, 1.0827, 1.2303, 1.3212, 1.0911, 2.0208, 1.0295, 0.7752, 0.9529,\n",
      "        1.7379, 0.8081, 1.4984, 1.5377, 0.4338, 0.8784, 1.0580, 2.2255, 1.8857,\n",
      "        1.3636, 1.3382])\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth_data[0][0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "251529d3-9577-4a38-bbef-e5b168589eb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.9969, -10.6170,   9.6952,  23.8715,   9.7822, -19.1298,  13.6094,\n",
      "         15.1885,  38.7057,  -8.2605,  -9.9273,  -0.1120,  31.9626, -12.8309,\n",
      "        -19.4600,  -6.4289,  26.7692,  -7.6756, -30.5661,   4.7903],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(dummy_matrix[0][0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0dacb5-9cba-48a1-ad7a-acf4d34cb249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
